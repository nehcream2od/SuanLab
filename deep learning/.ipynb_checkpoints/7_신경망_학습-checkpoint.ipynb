{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyjyu4FzUAVw"
      },
      "source": [
        "# 신경망 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQvNez4qydhL"
      },
      "source": [
        "## 단순한 신경망 구현 : Logic Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7te43hqyiiJ"
      },
      "source": [
        "### 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qf2F_YbdybBE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use([\"seaborn-v0_8-whitegrid\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orUoPmDcymhj"
      },
      "source": [
        "### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bOAmMxo0ymDF"
      },
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "lr = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjmLWgFVysnq"
      },
      "source": [
        "### 유틸 함수들(Util Functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y4OMFGrjyq1c"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "    return np.mean(np.square(true_y - pred_y))\n",
        "\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "    if true_y.ndim == 1:\n",
        "        true_y.reshape(1, -1)\n",
        "        pred_y.reshape(1, -1)\n",
        "    delta = 1e-7\n",
        "    return -np.sum(true_y * np.log(pred_y + delta))\n",
        "\n",
        "\n",
        "def cross_entropy_error_for_batch(pre):\n",
        "    if true_y.ndim == 1:\n",
        "        true_y.reshape(1, -1)\n",
        "        pred_y.reshape(1, -1)\n",
        "    delta = 1e-7\n",
        "    batch_size = pred_y.shape[0]\n",
        "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
        "\n",
        "\n",
        "def cross_entropy_for_binary(pred_y, true_y):\n",
        "    return 0.5 * np.sum(-true_y * np.log(pred_y) - (1 - true_y) * np.log(1 - pred_y))\n",
        "\n",
        "\n",
        "def softmax(a):\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def diffrential(f, x):\n",
        "    eps = 1e-5\n",
        "    diff_value = np.zeros_like(x)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        temp_val = x[i]\n",
        "\n",
        "        x[i] = temp_val + eps\n",
        "        f_h1 = f(x)\n",
        "\n",
        "        x[i] = temp_val - eps\n",
        "        f_h2 = f(x)\n",
        "\n",
        "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "        x[i] = temp_val\n",
        "    return diff_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Z2LTT_y3i5"
      },
      "source": [
        "### 신경망"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gMTjjYgdy3D8"
      },
      "outputs": [],
      "source": [
        "class LogicGateNet:\n",
        "    def __init__(self):\n",
        "        def weight_init():\n",
        "            np.random.seed(1)\n",
        "            weights = np.random.randn(2)\n",
        "            bias = np.random.rand(1)\n",
        "\n",
        "            return weights, bias\n",
        "\n",
        "        self.weights, self.bias = weight_init()\n",
        "\n",
        "    def predict(self, x):\n",
        "        W = self.weights.reshape(-1, 1)\n",
        "        b = self.bias\n",
        "\n",
        "        pred_y = sigmoid(np.dot(x, W) + b)\n",
        "        return pred_y\n",
        "\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_for_binary(pred_y, true_y)\n",
        "\n",
        "    def get_gradient(self, x, t):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, t)\n",
        "\n",
        "        grad_W = diffrential(loss_grad, self.weights)\n",
        "        grad_B = diffrential(loss_grad, self.bias)\n",
        "\n",
        "        return grad_W, grad_B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNDoH_3zbGZ"
      },
      "source": [
        "### AND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P-ib8_RzHTh"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rRiaACA6zGom"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 0.6886489498069661, Weights: [1.56426876 0.79168393], Bias: [-2.14871589]\n",
            "Epoch: 200, Cost: 0.49463686030634624, Weights: [2.01360719 1.71241131], Bias: [-3.07894028]\n",
            "Epoch: 300, Cost: 0.3920165980757264, Weights: [2.42841657 2.29753793], Bias: [-3.79103207]\n",
            "Epoch: 400, Cost: 0.3257214374794811, Weights: [2.794852   2.73235738], Bias: [-4.37257095]\n",
            "Epoch: 500, Cost: 0.27863601334727917, Weights: [3.11636193 3.08408364], Bias: [-4.86571237]\n",
            "Epoch: 600, Cost: 0.2432850468380881, Weights: [3.40015395 3.38235762], Bias: [-5.29433736]\n",
            "Epoch: 700, Cost: 0.21572536552440752, Weights: [3.65300561 3.64264217], Bias: [-5.67349792]\n",
            "Epoch: 800, Cost: 0.1936324442833927, Weights: [3.88044124 3.87412053], Bias: [-6.01340133]\n",
            "Epoch: 900, Cost: 0.17553213127892173, Weights: [4.08680123 4.08279091], Bias: [-6.32133891]\n",
            "Epoch: 1000, Cost: 0.16043926933294644, Weights: [4.27548114 4.27284863], Bias: [-6.6027234]\n"
          ]
        }
      ],
      "source": [
        "AND = LogicGateNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "for i in range(epochs):\n",
        "    grad_W, grad_B = AND.get_gradient(X, Y)\n",
        "\n",
        "    AND.weights -= lr * grad_W\n",
        "    AND.bias -= lr * grad_B\n",
        "\n",
        "    loss = AND.loss(X, Y)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(f\"Epoch: {i + 1}, Cost: {loss}, Weights: {AND.weights}, Bias: {AND.bias}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoyQv_czT7R"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-7CvWgc9zREa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.00135483]\n",
            " [0.08867878]\n",
            " [0.08889176]\n",
            " [0.87496677]]\n"
          ]
        }
      ],
      "source": [
        "print(AND.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMXNiXWzts-"
      },
      "source": [
        "### OR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ79pc4jzw3O"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8gnLmAyQzuoL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 0.4958092384805384, Weights: [2.45484353 1.40566594], Bias: [-0.14439625]\n",
            "Epoch: 200, Cost: 0.33986742315139534, Weights: [2.98631846 2.39448393], Bias: [-0.67661178]\n",
            "Epoch: 300, Cost: 0.25733609861876056, Weights: [3.45016595 3.08431266], Bias: [-1.03721585]\n",
            "Epoch: 400, Cost: 0.20630142190078646, Weights: [3.85230067 3.60865952], Bias: [-1.30598633]\n",
            "Epoch: 500, Cost: 0.17165499221171784, Weights: [4.20195872 4.03000824], Bias: [-1.52060015]\n",
            "Epoch: 600, Cost: 0.14665018845517636, Weights: [4.50867681 4.38171478], Bias: [-1.6994397]\n",
            "Epoch: 700, Cost: 0.12779768649489578, Weights: [4.78049264 4.68334611], Bias: [-1.8527641]\n",
            "Epoch: 800, Cost: 0.11310517185455744, Weights: [5.0237707 4.9472786], Bias: [-1.98691756]\n",
            "Epoch: 900, Cost: 0.1013518091840462, Weights: [5.24347159 5.18181684], Bias: [-2.10611973]\n",
            "Epoch: 1000, Cost: 0.09174843008630013, Weights: [5.44346811 5.39279833], Bias: [-2.21332947]\n"
          ]
        }
      ],
      "source": [
        "OR = LogicGateNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_2 = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "    grad_W, grad_B = OR.get_gradient(X, Y_2)\n",
        "\n",
        "    OR.weights -= lr * grad_W\n",
        "    OR.bias -= lr * grad_B\n",
        "\n",
        "    loss = OR.loss(X, Y_2)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(f\"Epoch: {i + 1}, Cost: {loss}, Weights: {OR.weights}, Bias: {OR.bias}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWmEtX_VnLSI"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JwPpOs3-z2vU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.09855987]\n",
            " [0.9600543 ]\n",
            " [0.96195283]\n",
            " [0.9998201 ]]\n"
          ]
        }
      ],
      "source": [
        "print(OR.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEBhczCIz57Q"
      },
      "source": [
        "### NAND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzQaaHKKz8sZ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h463QUQRz8PS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 0.7911738653764443, Weights: [-0.48972722 -1.25798774], Bias: [1.74566135]\n",
            "Epoch: 200, Cost: 0.543049095787227, Weights: [-1.51545093 -1.80261804], Bias: [2.79151756]\n",
            "Epoch: 300, Cost: 0.4212591302732214, Weights: [-2.14614496 -2.26642639], Bias: [3.56506179]\n",
            "Epoch: 400, Cost: 0.34561171015284464, Weights: [-2.607325   -2.66303355], Bias: [4.18521187]\n",
            "Epoch: 500, Cost: 0.29312986051864726, Weights: [-2.97696333 -3.00501941], Bias: [4.70528682]\n",
            "Epoch: 600, Cost: 0.25433967860044465, Weights: [-3.28850585 -3.30365261], Bias: [5.1539571]\n",
            "Epoch: 700, Cost: 0.22443918596815465, Weights: [-3.55912171 -3.56778782], Bias: [5.54869527]\n",
            "Epoch: 800, Cost: 0.2006762633083388, Weights: [-3.7989077  -3.80411461], Bias: [5.90108417]\n",
            "Epoch: 900, Cost: 0.18134125517652172, Weights: [-4.01441395 -4.01767547], Bias: [6.21926514]\n",
            "Epoch: 1000, Cost: 0.16530944081746007, Weights: [-4.21019696 -4.21231432], Bias: [6.50920952]\n"
          ]
        }
      ],
      "source": [
        "NAND = LogicGateNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_3 = np.array([[1], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "    grad_W, grad_B = NAND.get_gradient(X, Y_3)\n",
        "\n",
        "    NAND.weights -= lr * grad_W\n",
        "    NAND.bias -= lr * grad_B\n",
        "\n",
        "    loss = NAND.loss(X, Y_3)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\n",
        "            f\"Epoch: {i + 1}, Cost: {loss}, Weights: {NAND.weights}, Bias: {NAND.bias}\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR-rHaTU0Mga"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WpzKW6sm0Ghp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.99851256]\n",
            " [0.90861957]\n",
            " [0.90879523]\n",
            " [0.12861037]]\n"
          ]
        }
      ],
      "source": [
        "print(NAND.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTWfSQ60Zl2"
      },
      "source": [
        "### XOR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmmL0VIu0bXq"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0CGm0r1M0a9M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 1.402685224545991, Weights: [ 0.47012771 -0.19931523], Bias: [-0.16097708]\n",
            "Epoch: 200, Cost: 1.3879445622846385, Weights: [ 0.1572739  -0.03387161], Bias: [-0.07321056]\n",
            "Epoch: 300, Cost: 1.3864920300483725, Weights: [0.05525161 0.00089673], Bias: [-0.03330094]\n",
            "Epoch: 400, Cost: 1.3863236205351854, Weights: [0.02049628 0.00504503], Bias: [-0.01514784]\n",
            "Epoch: 500, Cost: 1.3862994743646784, Weights: [0.0080051  0.00361297], Bias: [-0.00689034]\n",
            "Epoch: 600, Cost: 1.386295343068745, Weights: [0.00326661 0.00201812], Bias: [-0.00313421]\n",
            "Epoch: 700, Cost: 1.3862945581495085, Weights: [0.00137938 0.00102449], Bias: [-0.00142566]\n",
            "Epoch: 800, Cost: 1.3862944013903702, Weights: [0.00059716 0.00049628], Bias: [-0.00064849]\n",
            "Epoch: 900, Cost: 1.3862943694120307, Weights: [0.00026303 0.00023435], Bias: [-0.00029498]\n",
            "Epoch: 1000, Cost: 1.3862943628323519, Weights: [0.0001172  0.00010905], Bias: [-0.00013418]\n"
          ]
        }
      ],
      "source": [
        "XOR = LogicGateNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_4 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "    grad_W, grad_B = XOR.get_gradient(X, Y_4)\n",
        "\n",
        "    XOR.weights -= lr * grad_W\n",
        "    XOR.bias -= lr * grad_B\n",
        "\n",
        "    loss = XOR.loss(X, Y_4)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(f\"Epoch: {i + 1}, Cost: {loss}, Weights: {XOR.weights}, Bias: {XOR.bias}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-ktElI0o5P"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GWAJAJ_T0oqm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.49996646]\n",
            " [0.49999372]\n",
            " [0.49999575]\n",
            " [0.50002302]]\n"
          ]
        }
      ],
      "source": [
        "print(XOR.predict(X))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XOR게이트는 학습에 실패한 모습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlq_-6E1nIq"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(1)\n",
        "\n",
        "- 얕은 신경망, Shallow Neural Network\n",
        "\n",
        "- 두 논리게이트(NAND, OR)를 통과하고  \n",
        "  AND 게이트로 합쳐서 구현\n",
        "\n",
        "- 06 신경망 구조 참고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mr7nYMG20jTo"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "s1 = NAND.predict(X)\n",
        "s2 = OR.predict(X)\n",
        "X_2 = np.array([s1, s2]).T.reshape(-1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTDx8Ah1xHY"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LK2iD5A91yWQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.12870357]\n",
            " [0.79966936]\n",
            " [0.80108545]\n",
            " [0.14420781]]\n"
          ]
        }
      ],
      "source": [
        "print(AND.predict(X_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-SK4G262Agn"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(2)\n",
        "- 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8RpnHCRZ1zwr"
      },
      "outputs": [],
      "source": [
        "class XORNet:\n",
        "    def __init__(self):\n",
        "        np.random.seed(1)\n",
        "\n",
        "        def weight_init():\n",
        "            params = {}\n",
        "            params[\"w_1\"] = np.random.randn(2)\n",
        "            params[\"b_1\"] = np.random.rand(2)\n",
        "            params[\"w_2\"] = np.random.randn(2)\n",
        "            params[\"b_2\"] = np.random.rand(1)\n",
        "            return params\n",
        "\n",
        "        self.params = weight_init()\n",
        "\n",
        "    def predict(self, x):\n",
        "        W_1, W_2 = self.params[\"w_1\"].reshape(-1, 1), self.params[\"w_2\"].reshape(-1, 1)\n",
        "        B_1, B_2 = self.params[\"b_1\"], self.params[\"b_2\"]\n",
        "\n",
        "        A1 = np.dot(x, W_1) + B_1\n",
        "        Z1 = sigmoid(A1)\n",
        "        A2 = np.dot(Z1, W_2) + B_2\n",
        "        pred_y = sigmoid(A2)\n",
        "\n",
        "        return pred_y\n",
        "\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_for_binary(pred_y, true_y)\n",
        "\n",
        "    def get_gradient(self, x, t):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads[\"w_1\"] = diffrential(loss_grad, self.params[\"w_1\"])\n",
        "        grads[\"b_1\"] = diffrential(loss_grad, self.params[\"b_1\"])\n",
        "        grads[\"w_2\"] = diffrential(loss_grad, self.params[\"w_2\"])\n",
        "        grads[\"b_2\"] = diffrential(loss_grad, self.params[\"b_2\"])\n",
        "\n",
        "        return grads\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lplK_x0l2YLh"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)\n",
        "- 재조정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qf-3wWSv2b7l"
      },
      "outputs": [],
      "source": [
        "lr = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHKd45d2JbJ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cQNd3XVd2Gj7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 1.3535614442467345\n",
            "Epoch: 200, Cost: 1.282715456832968\n",
            "Epoch: 300, Cost: 0.8968907892101325\n",
            "Epoch: 400, Cost: 0.3387197141164171\n",
            "Epoch: 500, Cost: 0.18121344475985138\n",
            "Epoch: 600, Cost: 0.11991186457241117\n",
            "Epoch: 700, Cost: 0.08861936864705311\n",
            "Epoch: 800, Cost: 0.06992180653055878\n",
            "Epoch: 900, Cost: 0.05758041353029885\n",
            "Epoch: 1000, Cost: 0.04886093568430801\n"
          ]
        }
      ],
      "source": [
        "XOR = XORNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = XOR.get_gradient(X, Y_5)\n",
        "\n",
        "    for key in (\"w_1\", \"b_1\", \"w_2\", \"b_2\"):\n",
        "        XOR.params[key] -= lr * grads[key]\n",
        "\n",
        "    loss = XOR.loss(X, Y_5)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(f\"Epoch: {i + 1}, Cost: {loss}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIV_GsoG2eDs"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Dpr0nZhc2Szr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0217367 ]\n",
            " [0.96884394]\n",
            " [0.97816819]\n",
            " [0.0217794 ]]\n"
          ]
        }
      ],
      "source": [
        "print(XOR.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1IuDL8R7wrx"
      },
      "source": [
        "## 다중 클래스 분류 : MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CiJ5Gmq9Wpa"
      },
      "source": [
        "### 배치 처리\n",
        "- 학습 데이터 전체를 한번에 진행하지 않고  \n",
        "  일부 데이터(샘플)을 확률적으로 구해서 조금씩 나누어 진행\n",
        "\n",
        "- 확률적 경사 하강법(Stochastic Gradient Descent) 또는  \n",
        "  미니 배치 학습법(mini-batch learning)이라고도 부름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUDNWwj49byH"
      },
      "source": [
        "#### 신경망 구현 : MNIST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjBRQYlP74GM"
      },
      "source": [
        "#### 필요한 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h0lJbkuW71lm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDvtEiD77_gu"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4WL7zXMl_uo9"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_rNg5Jn8FRA"
      },
      "source": [
        "#### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u4wpsQGA8BOO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pU7nvkHO8IFR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x17dfbd130>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = x_train[0]\n",
        "print(img.shape)\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WbBA1Kl18KGT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTFu8i-z8U_C"
      },
      "source": [
        "#### 데이터 전처리 (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "q76pjKDVftHJ"
      },
      "outputs": [],
      "source": [
        "def flatten_for_mnist(x):\n",
        "    temp = np.zeros((x.shape[0], x[0].size))  # 3차원을 2차원으로\n",
        "\n",
        "    for idx, data in enumerate(x):\n",
        "        temp[idx, :] = data.flatten()\n",
        "\n",
        "    return temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vvMWrDOR8Mns"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = flatten_for_mnist(x_train)\n",
        "x_test = flatten_for_mnist(x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train_ohe = tf.one_hot(y_train, depth=10).numpy()\n",
        "y_test_ohe = tf.one_hot(y_test, depth=10).numpy()\n",
        "\n",
        "print(y_train_ohe.shape)\n",
        "print(y_test_ohe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 0.0\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0].max(), x_train[0].min())\n",
        "print(y_train_ohe[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUaa92Y9RhY"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sk3FXXLi9Th5"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "lr = 0.1\n",
        "batch_size = 100\n",
        "train_size = x_train.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lMJ0h8p8iZl"
      },
      "source": [
        "#### 사용되는 함수들(Util Functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bSlqZ2Xx8hFn"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "    return np.mean(np.square(true_y - pred_y))\n",
        "\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "    if true_y.ndim == 1:\n",
        "        true_y.reshape(1, -1)\n",
        "        pred_y.reshape(1, -1)\n",
        "    delta = 1e-7\n",
        "    return -np.sum(true_y * np.log(pred_y + delta))\n",
        "\n",
        "\n",
        "def cross_entropy_error_for_batch(pre):\n",
        "    if true_y.ndim == 1:\n",
        "        true_y.reshape(1, -1)\n",
        "        pred_y.reshape(1, -1)\n",
        "    delta = 1e-7\n",
        "    batch_size = pred_y.shape[0]\n",
        "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
        "\n",
        "\n",
        "def cross_entropy_for_binary(pred_y, true_y):\n",
        "    return 0.5 * np.sum(-true_y * np.log(pred_y) - (1 - true_y) * np.log(1 - pred_y))\n",
        "\n",
        "\n",
        "def softmax(a):\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def diffrential_1d(f, x):\n",
        "    eps = 1e-5\n",
        "    diff_value = np.zeros_like(x)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        temp_val = x[i]\n",
        "\n",
        "        x[i] = temp_val + eps\n",
        "        f_h1 = f(x)\n",
        "\n",
        "        x[i] = temp_val - eps\n",
        "        f_h2 = f(x)\n",
        "\n",
        "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "        x[i] = temp_val\n",
        "\n",
        "    return diff_value\n",
        "\n",
        "\n",
        "def diffrential_2d(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return diffrential_1d(f, X)\n",
        "    else:\n",
        "        grad = np.zeros_like(X)\n",
        "\n",
        "        for idx, x in enumerate(X):\n",
        "            grad[idx] = diffrential_1d(f, X)\n",
        "\n",
        "        return grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoV9fyj8_u7"
      },
      "source": [
        "#### 2층 신경망으로 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XBObD5Fw89HI"
      },
      "outputs": [],
      "source": [
        "class MyModel:\n",
        "    def __init__(self):\n",
        "        def weight_init(input_nodes, hidden_nodes, output_units):\n",
        "            np.random.seed(777)\n",
        "\n",
        "            params = {}\n",
        "            params[\"w_1\"] = 0.01 * np.random.randn(input_nodes, hidden_nodes)\n",
        "            params[\"b_1\"] = np.zeros(hidden_nodes)\n",
        "            params[\"w_2\"] = 0.01 * np.random.randn(hidden_nodes, output_units)\n",
        "            params[\"b_2\"] = np.zeros(output_units)\n",
        "\n",
        "            return params\n",
        "\n",
        "        self.params = weight_init(784, 64, 10)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W_1, W_2 = self.params[\"w_1\"], self.params[\"w_2\"]\n",
        "        B_1, B_2 = self.params[\"b_1\"], self.params[\"b_2\"]\n",
        "\n",
        "        A1 = np.dot(x, W_1) + B_1\n",
        "        Z1 = sigmoid(A1)\n",
        "        A2 = np.dot(Z1, W_2) + B_2\n",
        "        pred_y = softmax(A2)\n",
        "\n",
        "        return pred_y\n",
        "\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_for_binary(pred_y, true_y)\n",
        "\n",
        "    def accuracy(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        y_argmax = np.argmax(pred_y, axis=1)\n",
        "        t_argmax = np.argmax(true_y, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y_argmax == t_argmax) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    def get_gradient(self, x, t):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads[\"w_1\"] = diffrential_2d(loss_grad, self.params[\"w_1\"])\n",
        "        grads[\"b_1\"] = diffrential_2d(loss_grad, self.params[\"b_1\"])\n",
        "        grads[\"w_2\"] = diffrential_2d(loss_grad, self.params[\"w_2\"])\n",
        "        grads[\"b_2\"] = diffrential_2d(loss_grad, self.params[\"b_2\"])\n",
        "\n",
        "        return grads\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maKNIlK-xJ5k"
      },
      "source": [
        "#### 모델 생성 및 학습\n",
        "- 시간 많이 소요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XSEARgNIop8t"
      },
      "outputs": [],
      "source": [
        "model = MyModel()\n",
        "\n",
        "train_loss_list = list()\n",
        "train_acc_list = list()\n",
        "test_acc_list = list()\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "start_time = time.time()\n",
        "for i in tqdm(range(epochs)):\n",
        "    batch_idx = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_idx]\n",
        "    y_batch = y_train_ohe[batch_idx]\n",
        "\n",
        "    grads = model.get_gradient(x_batch, y_batch)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        model.params[key] -= lr * grads[key]\n",
        "\n",
        "    loss = model.loss(x_batch, y_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    train_accuracy = model.accuracy(x_train, y_train_ohe)\n",
        "    test_accuracy = model.accuracy(x_test, y_train_ohe)\n",
        "    train_acc_list.append(train_accuracy)\n",
        "    test_acc_list.append(test_accuracy)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch: {i + 1}, Cost: {loss}, Train Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}\"\n",
        "    )\n",
        "end_time = time.time()\n",
        "print(f\"총 학습 소요시간: {end_time - start_time:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7nL8f20x4zl"
      },
      "source": [
        "### 모델의 결과\n",
        "- 모델은 학습이 잘 될 수도, 잘 안될 수도 있음\n",
        "\n",
        "- 만약, 학습이 잘 되지 않았다면,  \n",
        "  학습이 잘 되기 위해서 어떠한 조치를 취해야 하는가?\n",
        "  - 다양한 학습관련 기술이 존재"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "7c15afef78f50668981ba711ec2661f2a5596a86ec48569938de9a5d0b5f4743"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
